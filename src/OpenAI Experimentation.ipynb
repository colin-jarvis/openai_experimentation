{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respiratory-chancellor",
   "metadata": {},
   "source": [
    "# OpenAI Experimentation\n",
    "\n",
    "The purpose of this notebook is to try out the different OpenAI features to familiarise myself with them, with the ultimate aim of using GPT-3 for Named Entity Recognition to anonymise our care notes reliably for analytics.\n",
    "\n",
    "The features tested will be:\n",
    "- Completion: Training GPT-3 to response to prompts to perform useful tasks\n",
    "\n",
    "https://beta.openai.com/docs/guides/completion/introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-detection",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This step contains any imports and common setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "senior-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from helpers import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defined-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-fellowship",
   "metadata": {},
   "source": [
    "## Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-national",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chinese-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"? (Ne-Yo)\\n\\nYou're all like a picture perfect\\n\\nLike it's written in the stars\\n\\nI'm all like a common picture\\n\\nThere's no love in my heart?\\n\\n'Co 'co '\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1646243128,\n",
      "  \"id\": \"cmpl-4hNKSl2Yf2nE3gHBDiULIdrdfNhpz\",\n",
      "  \"model\": \"davinci:2020-05-03\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "phrase = 'Are you a real person'\n",
    "\n",
    "response = openai.Completion.create(engine=\"davinci\", prompt=phrase, max_tokens=50)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-ancient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" heard somebody say \\\"I don't like this girl, she's very bossy and [she] talks for England\\\",\\ntherefore she decided to talk for Scotland. \\n\\nCallie met a giant, who showed her the tallest building in the world. The Eiffel Tower was built about 28 years later, but it's not as tall. \\n\\nOne day she saw a tortoise, and it ran away; she then saw an eagle, which flew from side to side\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1646243132,\n",
      "  \"id\": \"cmpl-4hNKWupOw94aFYi0BfFuxjcNrugMx\",\n",
      "  \"model\": \"davinci:2020-05-03\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "song = '''There was once a brave young girl named Callie. She lived in a middle-class neighbourhood in Glasgow, \n",
    "so life had never been tougher. \n",
    "\n",
    "One day she'''\n",
    "\n",
    "song_response = openai.Completion.create(engine=\"davinci\", prompt=song, max_tokens=100)\n",
    "\n",
    "print(song_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "searching-florence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" \\n\\nDid she live in York? \\n\\nDid she live in York? \\n\\nHow many family members did she have? \\n\\nCallie didn't hate her life \\u2014 \\n\\nwhat she hated instead was \\n\\nthe love she gave.\\n\\nNot in the way the health visitor taught in spring. Not in the way that girl said it in her favourite film. But the kind that they can never get back. The kind that you give to the people\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1646243136,\n",
      "  \"id\": \"cmpl-4hNKa6iNL2aX96MZX6jZ3EqIA4bVt\",\n",
      "  \"model\": \"davinci:2020-05-03\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = '''There was once a brave young girl named Callie. She lived in a middle-class neighbourhood in Glasgow, \n",
    "so life had never been tougher. \n",
    "\n",
    "Where did Callie live?'''\n",
    "\n",
    "question_response = openai.Completion.create(engine=\"davinci\", prompt=question, max_tokens=100)\n",
    "\n",
    "print(question_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-tsunami",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was once a brave young girl named Callie. She lived in a middle-class neighbourhood in Glasgow, \n",
      "so life had never been tougher. \n",
      "\n",
      "Where did Callie live? \n",
      "\n",
      "Did she live in York? \n",
      "\n",
      "Did she live in York? \n",
      "\n",
      "How many family members did she have? \n",
      "\n",
      "Callie didn't hate her life â€” \n",
      "\n",
      "what she hated instead was \n",
      "\n",
      "the love she gave.\n",
      "\n",
      "Not in the way the health visitor taught in spring. Not in the way that girl said it in her favourite film. But the kind that they can never get back. The kind that you give to the people\n"
     ]
    }
   ],
   "source": [
    "print(question + question_response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-charger",
   "metadata": {},
   "source": [
    "### ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = '''Customer: Hi, I'd like to speak to Sales.\n",
    "                  Bot: Of course, but can I ask you some questions first so I can get you to the right place?\n",
    "                  Customer: No\n",
    "                  Bot:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fleet-thomas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-4hNKfpKHZRF2c9KXOFs6nxDFcQkfy at 0x114f96d70> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Ok, May I ask you where are you now?\\n                Customer: In the sales center\\n\\nArtificial intelligence can be found in corporations assisting concierge doctors by\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1646243141,\n",
       "  \"id\": \"cmpl-4hNKfpKHZRF2c9KXOFs6nxDFcQkfy\",\n",
       "  \"model\": \"davinci:2020-05-03\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response = openai.Completion.create(engine=\"davinci\", prompt=conversation, max_tokens=50)\n",
    "\n",
    "chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hazardous-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer: Hi, I'd like to speak to Sales.\n",
      "                  Bot: Of course, but can I ask you some questions first so I can get you to the right place?\n",
      "                  Customer: No\n",
      "                  Bot: Ok, May I ask you where are you now?\n",
      "                Customer: In the sales center\n",
      "\n",
      "Artificial intelligence can be found in corporations assisting concierge doctors by\n"
     ]
    }
   ],
   "source": [
    "print(conversation + chat_response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sunset-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,6):\n",
    "    chat_response = openai.Completion.create(engine=\"davinci\", prompt=conversation, max_tokens=50)\n",
    "\n",
    "    conversation += chat_response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "religious-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer: Hi, I'd like to speak to Sales.\n",
      "                  Bot: Of course, but can I ask you some questions first so I can get you to the right place?\n",
      "                  Customer: No\n",
      "                  Bot: Then we don't have much to talk about. \n",
      "\n",
      "                 \n",
      "Interrogative <br> \n",
      "\n",
      "Asking questions.\n",
      "\n",
      "Customer: Do you sell generic drugs?\n",
      "               Yes, we do.         No, we don't. <br> \n",
      "\n",
      "Asking for prices.\n",
      "\n",
      "                We sell the best quality generic drugs.          <br> \n",
      "\n",
      "Support <br> \n",
      "\n",
      "Giving system information\n",
      "\n",
      " \n",
      "Customer: www.hellobot.com? \n",
      "            Bot: That page couldn't be found. \n",
      "\n",
      " \n",
      "   Customer: I'd like information on how to use Hello, Bot! messaging service. \n",
      "               Bot: Please contact the person who is managing Hello, Bot! messaging service. \n",
      "\n",
      "         \n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-bahrain",
   "metadata": {},
   "source": [
    "## Updated Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "weird-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_conversation = '''\n",
    "                  Customer Company: everyLIFE Technologies\n",
    "                  Customer Sector: Health & Social Care\n",
    "                  Sales Representative for Health & Social Care Sector: Sandra\n",
    "                  Sales Representative for Energy Sector: Tom\n",
    "                  \n",
    "                  The Bot should determine the cause of the Customer's inquiry and then forward them to the right sales representative for the sector.\n",
    "                  If we do not have a Sales Representative for the Sector then connect them to Customer Services.\n",
    "                  \n",
    "                  \n",
    "                  Customer: Hi, I'd like to speak to Sales.\n",
    "                  Bot: Of course, but can I ask you some questions first so I can get you to the right place?\n",
    "                  Customer: Yes sure\n",
    "                  Bot:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abstract-religion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-4hNKvWNUxToTDalHISCkXGBBoR7fc at 0x114fb0dd0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" What is the purpose of your inquiry?\\n                  Customer: I'm interested in purchasing a product.\\n             \"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1646243157,\n",
       "  \"id\": \"cmpl-4hNKvWNUxToTDalHISCkXGBBoR7fc\",\n",
       "  \"model\": \"text-davinci:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_chat_response = openai.Completion.create(engine=\"davinci-instruct-beta-v3\", prompt=pos_conversation, max_tokens=50)\n",
    "\n",
    "pos_chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "running-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,6):\n",
    "    pos_chat_response = openai.Completion.create(engine=\"davinci-instruct-beta-v3\", prompt=pos_conversation, max_tokens=50)\n",
    "\n",
    "    pos_conversation += pos_chat_response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sensitive-transportation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  Customer Company: everyLIFE Technologies\n",
      "                  Customer Sector: Health & Social Care\n",
      "                  Sales Representative for Health & Social Care Sector: Sandra\n",
      "                  Sales Representative for Energy Sector: Tom\n",
      "                  \n",
      "                  The Bot should determine the cause of the Customer's inquiry and then forward them to the right sales representative for the sector.\n",
      "                  If we do not have a Sales Representative for the Sector then connect them to Customer Services.\n",
      "                  \n",
      "                  \n",
      "                  Customer: Hi, I'd like to speak to Sales.\n",
      "                  Bot: Of course, but can I ask you some questions first so I can get you to the right place?\n",
      "                  Customer: Yes sure\n",
      "                  Bot: What industry is your company in?\n",
      "                  Customer: Energy\n",
      "                  Bot: We don't have a Sales Representative for the Energy Sector, but I can connect you to our Customer Services team. Is that okay?\n",
      "                  Customer: Yes, that's fine.\n"
     ]
    }
   ],
   "source": [
    "print(pos_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "systematic-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_conversation = '''\n",
    "                  Customer Company: everyLIFE Technologies\n",
    "                  Customer Sector: Health & Social Care\n",
    "                  Sales Representative for Health & Social Care Sector: Sandra\n",
    "                  Sales Representative for Energy Sector: Tom\n",
    "                  \n",
    "                  The Bot should determine the cause of the Customer's inquiry and then forward them to the right sales representative for the sector.\n",
    "                  If we do not have a Sales Representative for the Sector then connect them to Customer Services.\n",
    "                  \n",
    "                  \n",
    "                  Customer: Hi, I'd like to speak to Sales.\n",
    "                  Bot: Of course, but can I ask you some questions first so I can get you to the right place?\n",
    "                  Customer: No, I want to talk to a person\n",
    "                  Bot:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "flush-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,6):\n",
    "    neg_chat_response = openai.Completion.create(engine=\"davinci-instruct-beta-v3\", prompt=neg_conversation, max_tokens=50)\n",
    "\n",
    "    neg_conversation += neg_chat_response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accurate-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  Customer Company: everyLIFE Technologies\n",
      "                  Customer Sector: Health & Social Care\n",
      "                  Sales Representative for Health & Social Care Sector: Sandra\n",
      "                  Sales Representative for Energy Sector: Tom\n",
      "                  \n",
      "                  The Bot should determine the cause of the Customer's inquiry and then forward them to the right sales representative for the sector.\n",
      "                  If we do not have a Sales Representative for the Sector then connect them to Customer Services.\n",
      "                  \n",
      "                  \n",
      "                  Customer: Hi, I'd like to speak to Sales.\n",
      "                  Bot: Of course, but can I ask you some questions first so I can get you to the right place?\n",
      "                  Customer: No, I want to talk to a person\n",
      "                  Bot: I'm sorry, we don't have anyone in Sales at the moment. Would you like to speak to our Customer Services team instead?\n"
     ]
    }
   ],
   "source": [
    "print(neg_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-sampling",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "We want to remove personal names from this text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "similar-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "care_notes = '''\n",
    "\n",
    "    The care notes are:\n",
    "    \n",
    "    Alice is well in.herself this evening, made a cup tea on.my arrival and \n",
    "    put a frozen meal in the microwave and heated go manufacturers guidelines, \n",
    "    tonight's meal had too much rice. \n",
    "    Alice didn't enjoy all of the rice,washed up chatted and leaving Alice comfy with her cup of tea.\n",
    "    \n",
    "    Remove all personal names from the care notes and replace with Customer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "individual-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymised_care_notes = openai.Completion.create(engine=\"davinci-instruct-beta-v3\", prompt=care_notes, max_tokens=len(care_notes) + 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "welcome-microwave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The care notes are:\n",
      "\n",
      "Customer is well in herself this evening, made a cup tea on my arrival and put a frozen meal in the microwave and heated it to manufacturers guidelines, tonight's meal had too much rice. Customer didn't enjoy all of the rice, washed up chatted and leaving customer comfy with her cup of tea.\n"
     ]
    }
   ],
   "source": [
    "print(anonymised_care_notes['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "raised-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "care_notes_updated = '''\n",
    "\n",
    "    The care notes are:\n",
    "    \n",
    "    Alice is well in.herself this evening, made a cup tea on.my arrival and \n",
    "    put a frozen meal in the microwave and heated go manufacturers guidelines, \n",
    "    tonight's meal had too much rice. \n",
    "    Alice didn't enjoy all of the rice,washed up chatted and leaving Alice comfy with her cup of tea.\n",
    "    \n",
    "    Remove all personal names from the care notes and replace with Customer\n",
    "    Replace all pronouns with they/them\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "solar-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymised_better_care_notes = openai.Completion.create(engine=\"davinci-instruct-beta-v3\", prompt=care_notes_updated, max_tokens=len(care_notes) + 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "electric-wyoming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The care notes are:\n",
      "\n",
      "The customer is well this evening. They made a cup of tea when I arrived and put a frozen meal in the microwave according to the manufacturer's guidelines. Tonight's meal had too much rice. The customer didn't enjoy all of the rice, but they washed up and chatted. They left the customer comfortable with their cup of tea.\n"
     ]
    }
   ],
   "source": [
    "print(anonymised_better_care_notes['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-traffic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-spell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-affairs",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
